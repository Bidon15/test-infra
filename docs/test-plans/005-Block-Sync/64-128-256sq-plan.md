# Block Synchronization for 64/128/256 Square Size Block

We need to run experiments to know how fast will it be for the full node(s) to sync blocks from bridge nodes and from amongst themselves, as the blocks are being produced for
both IPLD and Shrex getters.

In this scenario we are only focusing on syncing, thus ignoring any other scenario (_such as attacks of any kind_)

## Pre-Requisite

| Block Square Size<br />`X` |            Bridge Nodes amount <br />`Y`             |  Full Nodes Amount <br />`Z` | Peer Limit <br />`W` |
| :---------------------------: | :-----------------------------------------: | :---------------------------: | :---------------------------: |
|              64               | 3 | 32 | 3 |  
|              128               |  3  | 32 | 3 | 

And For Historical Scenarios

| Block Square Size<br />`X` |            Bridge Nodes amount <br />`Y`             |  Full Nodes Amount <br />`Z` | Historical Full Nodes <br />`H` | Peer Limit <br />`W` |
| :---------------------------: | :-----------------------------------------: | :---------------------------: | :---------------------------: | :---------------------------: |
|              64               | 3 | 12 | 12 |   3 |  
|              128               |  3  | 12 | 12 |  3 |

## HW Resources setup for Block Square Size ==  64|128|256

We already know that we can count on 172 cores CPU and 700 GB of RAM to allocate for testable nodes
Hence, our network setup/HW allocation will look like this:

1. 1 Validators with each having 4 vCPU and 4 Gb
2. 3 Bridge Nodes with each having 4 vCPU and 8 Gb
3. 32 Full Nodes with each having 4 CPU and 8 Gb

## Network Bandwidth:

- Validator/Bridge/Full: 256Mib -- 50ms

## Network Topology

### All cases
For all cases, the singular validator is used for three bridges.

### Case 1 - Syncing Latest:

Z Full nodes all connected to exactly 1 or all of the existing Y bridges, and connected amongst themselves (_peerLimit is set to W_) such that full nodes are syncing latest blocks as they are being produced.

This will include three main networking variations for each full node's getter:

1. All bridges are bootstrappers
2. Bridges are not connected to each other on the start unless they discover each other during test time
3. Each full node is taking one bridge node as a trusted peer

### Case 2 - Syncing Latest with network partitions:

Z Full nodes all connected to exactly 1 or all of the existing Y bridges, and connected amongst themselves (_peerLimit is set to W_) such that full nodes are syncing latest blocks as they are being produced, with random full nodes being disconnecting from Bridge node a given random `network-partition-height`.

This will include the following networking setup each getter before the network partition:

1. All bridges are bootstrappers
2. Bridges are connected to each other on the start
3. Each full node is taking all bridge nodes as trusted peers

After the network partition, a set of randomly chosen full nodes will remain connected to a set of randomly chosen bridge nodes, while the rest of the full nodes will be disconnected from the bridge nodes,
to simulate a network partition.


### Case 3 - Syncing Historical:
  

Z Full nodes and H Historical Full Nodes are all connected to exactly 1 or all of the existing X bridges, and connected amongst themselves (_peerLimit is set to W_) such that historical full nodes do not come alive until bridge and full nodes have synced up to `target-height` from core network, to produce historical syncing behavior.

This will include three main networking variations for each getter:

1. All bridges are bootstrappers
2. Bridges are not connected to each other on the start unless they discover each other during test time
3. Each full node is taking one bridge node as a trusted peer

### Case 3 - Syncing Historical with network partitions:

Z Full nodes and H Historical Full Nodes are all connected to exactly 1 or all of the existing X bridges, and connected amongst themselves (_peerLimit is set to W_) such that historical full nodes do not come alive until bridge and fulls nodes have synced up to `target-height` from core network, to produce historical syncing behavior, with random full and historical nodes being disconnecting from Bridge node a given random `network-partition-height`.

This will include the following networking setup each getter before the network partition:

1. All bridges are bootstrappers
2. Bridges are connected to each other on the start
3. Each full/historical node is taking all bridge nodes as trusted peers

After the network partition, a set of randomly chosen full and historical nodes will remain connected to a set of randomly chosen bridge nodes, while the rest of the full nodes will be disconnected from the bridge nodes,
to simulate a network partition.